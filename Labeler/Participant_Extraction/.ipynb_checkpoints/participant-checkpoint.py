{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6130d89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/yifjia/ENTER/envs/tripPy/lib/python3.7/site-packages/spacy/util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.2.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x7f695e2321e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import pickle as pk\n",
    "import json\n",
    "import csv\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import Element\n",
    "from xml.etree.ElementTree import SubElement\n",
    "from xml.etree.ElementTree import ElementTree\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus.reader import Synset\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.lang.en import English\n",
    "nlp_sen = English()\n",
    "config = {\"punct_chars\": None}\n",
    "nlp_sen.add_pipe(\"sentencizer\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c9a7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConstructXml(nlp,sen,entity):\n",
    "    doc=nlp(sen)\n",
    "    pos_list=[t.pos_ for t in doc]\n",
    "    token_list=[t.lemma_ for t in doc]\n",
    "    word_list = [str(t) for t in doc]\n",
    "\n",
    "    TargetEntity = [entity]\n",
    "    print('ESC')\n",
    "    special_word = ['others','what','where','when','how','who','everything','call','number']\n",
    "    for special in special_word:\n",
    "        if entity in special:\n",
    "            return 0\n",
    "    corpus = Element('corpus')\n",
    "    corpus.attrib = {\"lang\":\"en\",\"source\":\"Test\"}\n",
    "    text = SubElement(corpus, 'text')\n",
    "    text.attrib = {\"id\":\"d000\"}\n",
    "    sentence = SubElement(text, 'sentence')\n",
    "    sentence.attrib = {\"id\":\"d000.s000\"}\n",
    "    for lem,pos,word in zip(token_list,pos_list,word_list):\n",
    "        temp_pos = 'NOUN'\n",
    "        if word in TargetEntity:\n",
    "            if pos == 'VERB' and 'ing' in entity:\n",
    "                return 0\n",
    "            \n",
    "            instance = SubElement(sentence, 'instance')\n",
    "            instance.attrib = {'id':'d000.s000.t00'+str(TargetEntity.index(word)),'lemma':word.lower(),'pos':temp_pos}\n",
    "            instance.text = str(word)\n",
    "        else:\n",
    "            wf = SubElement(sentence, 'wf')\n",
    "            wf.attrib = {'lemma':lem.lower(),'pos':temp_pos}\n",
    "            wf.text = word\n",
    "    file_handle = open(\"Test.data.xml\",\"wb\")\n",
    "    tree = ElementTree(corpus)\n",
    "    tree.write(file_handle)\n",
    "    file_handle.close()\n",
    "    \n",
    "    return 1\n",
    "    \n",
    "def checkPhysicalEsc(possible_entity):\n",
    "    special_word = ['others','what','where','when','how','who','everything','call','number']\n",
    "    for special in special_word:\n",
    "        if possible_entity.name() in special:\n",
    "            return 0\n",
    "    abstract_word = ['abstraction','abstract_entity','abstract','location','part','piece']\n",
    "    if len(possible_entity.hypernyms())!=0:\n",
    "        while True:\n",
    "            if len(possible_entity.hypernyms())!=0:\n",
    "                possible_entity=possible_entity.hypernyms()[0]\n",
    "#                 print(possible_entity.name())\n",
    "                for abstract in abstract_word:\n",
    "                    if possible_entity.name().split('.')[0] in abstract:\n",
    "                        return 0\n",
    "                if 'physical_entity' in possible_entity.name() or 'physical_object' in possible_entity.name():\n",
    "                    return 1\n",
    "            else:\n",
    "                return 2\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def PredictSynsets(dataset_path,tokenizer,args,wsd_model,prediction_type,debug=False):\n",
    "    dataset = WordNetDataset(\n",
    "    dataset_path, tokenizer, args['tokens_per_batch'], re_init_on_iter=False, is_test=True\n",
    "    )\n",
    "\n",
    "    data_loader = DataLoader(dataset, batch_size=None, num_workers=0)\n",
    "\n",
    "    prediction_report = predict(\n",
    "        model=wsd_model,\n",
    "        data_loader=data_loader,\n",
    "        device=args['device'],\n",
    "        prediction_type=prediction_type,\n",
    "        evaluate=args['evaluate'],\n",
    "    )\n",
    "    offset = prediction_report[0][0].predicted_synsets[0]\n",
    "    if debug:\n",
    "        print(prediction_report[0][0])\n",
    "        print(offset)\n",
    "    return checkPhysicalEsc(wn.of2ss(offset))\n",
    "\n",
    "def ESCCheck(nlp,sen,entity,dataset_path,tokenizer,args,wsd_model,prediction_type,debug=False):\n",
    "    result = ConstructXml(nlp,sen,entity)\n",
    "    if result == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return PredictSynsets(dataset_path,tokenizer,args,wsd_model,prediction_type,debug)\n",
    "\n",
    "def CheckAbstract(nlp,sen,entity,dataset_path,tokenizer,args,wsd_model,prediction_type,debug=False):\n",
    "    physicalFlag = False\n",
    "    for subentity in entity.split(\" \"):\n",
    "        try:\n",
    "            result = ESCCheck(nlp,sen,subentity,dataset_path,tokenizer,args,wsd_model,prediction_type,debug)\n",
    "            if result > 0:\n",
    "                physicalFlag = True\n",
    "        except:\n",
    "            physicalFlag = True\n",
    "            continue\n",
    "            \n",
    "    return physicalFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc107925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
