{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3cd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from www.utils import format_time\n",
    "from www.dataset.ann import att_to_num_classes\n",
    "import numpy as np\n",
    "from transformers import RobertaForMultipleChoice\n",
    "import progressbar\n",
    "from www.model.evalAdapt_V2 import evaluate_tiered\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "# Train a PyTorch model for one epoch\n",
    "def train_epoch(model,\n",
    "                optimizer,\n",
    "                train_dataloader,\n",
    "                device,\n",
    "                list_output=False,\n",
    "                num_outputs=1,\n",
    "                span_mode=False,\n",
    "                seg_mode=False,\n",
    "                classifier=None,\n",
    "                multitask_idx=None):\n",
    "    t0 = time.time()\n",
    "\n",
    "    if not list_output:\n",
    "        total_loss = 0\n",
    "    else:\n",
    "        total_loss = [0 for _ in range(num_outputs)]\n",
    "\n",
    "    # Training mode\n",
    "    model.train()\n",
    "\n",
    "    if len(train_dataloader) * train_dataloader.batch_size >= 2500:\n",
    "        progress_update = True\n",
    "    else:\n",
    "        progress_update = False\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Progress update\n",
    "        if progress_update and step % 50 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('\\t(%s) Starting batch %s of %s.' %\n",
    "                  (elapsed, str(step), str(len(train_dataloader))))\n",
    "\n",
    "        input_ids = batch[0].to(device)\n",
    "        input_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        # if input_ids.dim() > 2:\n",
    "        #   input_ids = input_ids.view(input_ids.shape[0], -1)\n",
    "        #   input_mask = input_mask.view(input_mask.shape[0], -1)\n",
    "\n",
    "        # In some cases, we also include a span for each training sequence which the model uses to classify only certain parts of the input\n",
    "        if span_mode:\n",
    "            spans = batch[3].to(device)\n",
    "        elif seg_mode:\n",
    "            segment_ids = batch[3].to(device)\n",
    "        else:\n",
    "            spans = None\n",
    "\n",
    "        # Forward pass\n",
    "        model.zero_grad()\n",
    "        if multitask_idx == None:\n",
    "            if span_mode:\n",
    "                out = model(input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=input_mask,\n",
    "                            labels=labels,\n",
    "                            spans=spans)\n",
    "            elif seg_mode:\n",
    "                out = model(input_ids,\n",
    "                            token_type_ids=segment_ids,\n",
    "                            attention_mask=input_mask,\n",
    "                            labels=labels)\n",
    "            else:\n",
    "                out = model(input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=input_mask,\n",
    "                            labels=labels)\n",
    "        else:\n",
    "            if span_mode:\n",
    "                out = model(input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=input_mask,\n",
    "                            labels=labels,\n",
    "                            spans=spans,\n",
    "                            task_idx=multitask_idx)\n",
    "            elif seg_mode:\n",
    "                out = model(input_ids,\n",
    "                            token_type_ids=segment_ids,\n",
    "                            attention_mask=input_mask,\n",
    "                            labels=labels,\n",
    "                            task_idx=multitask_idx)\n",
    "            else:\n",
    "                out = model(input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=input_mask,\n",
    "                            labels=labels,\n",
    "                            task_idx=multitask_idx)\n",
    "\n",
    "        if classifier != None:\n",
    "            sequence_output = out[0]\n",
    "            logits = classifier(out)\n",
    "\n",
    "            loss = None\n",
    "            if labels is not None:\n",
    "                if self.num_labels == 1:\n",
    "                    #  We are doing regression\n",
    "                    loss_fct = MSELoss()\n",
    "                    loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "                elif self.num_labels == 2:\n",
    "                    loss_fct = CrossEntropyLoss()\n",
    "                    loss = loss_fct(logits.view(-1, self.num_labels),\n",
    "                                    labels.view(-1))\n",
    "\n",
    "        else:\n",
    "            loss = out[0]\n",
    "\n",
    "        # Backward pass\n",
    "        if not list_output:\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "        else:\n",
    "            for o in range(num_outputs):\n",
    "                total_loss[o] += loss[o].item()\n",
    "                loss[o].backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
    "                                       1.0)  # Gradient clipping\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    if list_output:\n",
    "        return list(np.array(total_loss) / len(train_dataloader)), model\n",
    "    else:\n",
    "        return total_loss / len(train_dataloader), model\n",
    "\n",
    "\n",
    "def tslm_entity_classifier(tslmclassifier, input_ids, input_mask,\n",
    "                           timestep_type_ids, preconditions, effects,\n",
    "                           att_to_num_classes, tslm_optimizer):\n",
    "    embedding_result = torch.tensor([]).to(device)\n",
    "    pre_result = torch.tensor([]).to(device)  # output of classifiers\n",
    "    effect_result = torch.tensor([]).to(device)  # output of classifiers\n",
    "    pre_pred = torch.tensor([]).to(device)\n",
    "    effect_pred = torch.tensor([]).to(device)\n",
    "    num_attributes = len(att_to_num_classes)\n",
    "    input_ids_tslm = input_ids.view(-1, max_story_length, maxStoryLength)\n",
    "    input_mask_tslm = input_mask.view(-1, max_story_length, maxStoryLength)\n",
    "    timestep_tslm = timestep_type_ids.view(-1, max_story_length,\n",
    "                                           maxStoryLength)\n",
    "    preconditions_tslm = preconditions.view(-1, max_story_length,\n",
    "                                            num_attributes)\n",
    "    effects_tslm = effects.view(-1, max_story_length, num_attributes)\n",
    "    total_loss_pre = 0\n",
    "    total_loss_effect = 0\n",
    "    #     tslmclassifier.train()\n",
    "    #     for layer in tslmclassifier.precondition_classifiers:\n",
    "    #         layer.train()\n",
    "    #     for layer in tslmclassifier.effect_classifiers:\n",
    "    #         layer.train()\n",
    "    for entity_index in range(len(input_ids_tslm)):\n",
    "        tslmclassifier.zero_grad()\n",
    "        entity_input = input_ids_tslm[entity_index]\n",
    "        entity_mask = input_mask_tslm[entity_index]\n",
    "        entity_timestep = timestep_tslm[entity_index]\n",
    "        entity_preconditions = preconditions_tslm[entity_index]\n",
    "        entity_effects = effects_tslm[entity_index]\n",
    "        tslmclassifier.zero_grad()\n",
    "        entity_cls, pre_pred_tmp, effect_pred_tmp, pre_result_tmp, effect_result_tmp, loss_pre, loss_effect = tslmclassifier(\n",
    "            entity_input=entity_input,\n",
    "            entity_mask=entity_mask,\n",
    "            entity_timestep=entity_timestep,\n",
    "            entity_preconditions=entity_preconditions,\n",
    "            entity_effects=entity_effects)\n",
    "        with torch.no_grad():\n",
    "            pre_result = torch.cat((pre_result, pre_result_tmp), dim=0)\n",
    "            effect_result = torch.cat((effect_result, effect_result_tmp),\n",
    "                                      dim=0)\n",
    "            pre_pred = torch.cat((pre_pred, pre_pred_tmp), dim=0)\n",
    "            effect_pred = torch.cat((effect_pred, effect_pred_tmp), dim=0)\n",
    "            embedding_result = torch.cat((embedding_result, entity_cls), dim=0)\n",
    "        loss_pre = loss_pre / num_attributes\n",
    "        loss_effect = loss_effect / num_attributes\n",
    "        total_loss_pre += loss_pre\n",
    "        total_loss_effect += loss_effect\n",
    "        loss_entity = loss_pre + loss_effect\n",
    "        #         print(\"loss of {} entity is {}\".format(entity_index,loss_entity))\n",
    "        loss_entity.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(tslmclassifier.parameters(), 1.0)\n",
    "        tslm_optimizer.step()\n",
    "\n",
    "    total_loss_pre /= len(input_ids_tslm)\n",
    "    total_loss_effect /= len(input_ids_tslm)\n",
    "\n",
    "    return pre_result, effect_result, pre_pred, effect_pred, embedding_result, total_loss_pre, total_loss_effect\n",
    "\n",
    "\n",
    "# Train a state classification pipeline for one epoch\n",
    "def train_epoch_tiered(MaxStoryLength,\n",
    "                       tslm_model,\n",
    "                       trip_model,\n",
    "                       tslm_optimizer,\n",
    "                       trip_optimizer,\n",
    "                       train_dataloader,\n",
    "                       device,\n",
    "                       seg_mode=False,\n",
    "                       return_losses=False,\n",
    "                       build_learning_curves=False,\n",
    "                       val_dataloader=None,\n",
    "                       train_lc_data=None,\n",
    "                       val_lc_data=None):\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    # Training mode\n",
    "    tslm_model.train()\n",
    "    trip_model.train()\n",
    "    for layer in tslm_model.precondition_classifiers:\n",
    "        layer.train()\n",
    "    for layer in tslm_model.effect_classifiers:\n",
    "        layer.train()\n",
    "\n",
    "    # if len(train_dataloader) * train_dataloader.batch_size >= 2500:\n",
    "    #   progress_update = True\n",
    "    # else:\n",
    "    #   progress_update = False\n",
    "    progress_update = False\n",
    "\n",
    "    bar_size = len(train_dataloader)\n",
    "    bar = progressbar.ProgressBar(max_value=bar_size,\n",
    "                                  widgets=[\n",
    "                                      progressbar.Bar('#', '[', ']'), ' ',\n",
    "                                      progressbar.Percentage()\n",
    "                                  ])\n",
    "    bar_idx = 0\n",
    "    bar.start()\n",
    "\n",
    "    if train_lc_data is not None:\n",
    "        train_lc_data.append([])\n",
    "    if val_lc_data is not None:\n",
    "        val_lc_data.append([])\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Progress update\n",
    "        if progress_update and step % 50 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('\\t(%s) Starting batch %s of %s.' %\n",
    "                  (elapsed, str(step), str(len(train_dataloader))))\n",
    "\n",
    "        input_ids = batch[0].long().to(device)\n",
    "        input_lengths = batch[1].to(device)  #.to(torch.int64).to('cpu')\n",
    "        input_entities = batch[2].to(device)\n",
    "        input_mask = batch[3].to(device)\n",
    "        attributes = batch[4].long().to(device)\n",
    "        preconditions = batch[5].long().to(device)\n",
    "        effects = batch[6].long().to(device)\n",
    "        conflicts = batch[7].long().to(device)\n",
    "        labels = batch[8].long().to(device)\n",
    "        timestep_type_ids = batch[9].long().to(device)\n",
    "        if seg_mode:\n",
    "            segment_ids = batch[8].to(device)\n",
    "        else:\n",
    "            segment_ids = None\n",
    "\n",
    "        # Forward pass\n",
    "        tslm_model.zero_grad()\n",
    "        trip_model.zero_grad()\n",
    "\n",
    "        prec_result,effect_result,prec_pred,effect_pred,embedding_result,total_loss_pre,total_loss_effect=\\\n",
    "        tslm_entity_classifier(tslmclassifier,input_ids,input_mask,timestep_type_ids,preconditions,effects,att_to_num_classes,tslm_optimizer)\n",
    "\n",
    "        out = trip_model(embedding_result,\n",
    "                         input_ids.shape,\n",
    "                         input_lengths,\n",
    "                         input_entities,\n",
    "                         out_preconditions=prec_pred,\n",
    "                         out_preconditions_softmax=prec_result,\n",
    "                         out_effects=effect_pred,\n",
    "                         out_effects_softmax=effect_result,\n",
    "                         attention_mask=input_mask,\n",
    "                         token_type_ids=segment_ids,\n",
    "                         attributes=attributes,\n",
    "                         preconditions=preconditions,\n",
    "                         effects=effects,\n",
    "                         conflicts=conflicts,\n",
    "                         labels=labels,\n",
    "                         training=True)\n",
    "\n",
    "        out['loss_preconditions'] = total_loss_pre\n",
    "        out['loss_effects'] = total_loss_effect\n",
    "        train_loss = out['loss_stories'] + out['loss_conflicts']\n",
    "        temp_total_loss = train_loss + total_loss_pre + total_loss_effect\n",
    "        out['total_loss'] = temp_total_loss\n",
    "        train_loss.backward()\n",
    "        # Backward pass\n",
    "        total_loss += temp_total_loss.item()\n",
    "\n",
    "        #     torch.nn.utils.clip_grad_norm_(tslm_model.parameters(), 1.0) # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(trip_model.parameters(),\n",
    "                                       1.0)  # Gradient clipping\n",
    "\n",
    "        #     tslm_optimizer.step()\n",
    "        trip_optimizer.step()\n",
    "\n",
    "        # Build learning curve data if needed\n",
    "        if build_learning_curves:\n",
    "            train_record = {\n",
    "                'epoch':\n",
    "                len(train_lc_data) - 1,\n",
    "                'iteration':\n",
    "                (len(train_lc_data) - 1) * len(train_dataloader) + step,\n",
    "                'loss_preconditions':\n",
    "                float(out['loss_preconditions'].detach().cpu().numpy()) /\n",
    "                trip_model.num_attributes,\n",
    "                'loss_effects':\n",
    "                float(out['loss_effects'].detach().cpu().numpy()) /\n",
    "                trip_model.num_attributes,\n",
    "                'loss_conflicts':\n",
    "                float(out['loss_conflicts'].detach().cpu().numpy()),\n",
    "                'loss_stories':\n",
    "                float(out['loss_stories'].detach().cpu().numpy()),\n",
    "                'loss_total':\n",
    "                float(out['total_loss'].detach().cpu().numpy())\n",
    "            }\n",
    "            train_lc_data[-1].append(train_record)\n",
    "\n",
    "            # Add a validation record 5 times per epoch\n",
    "            chunk_size = len(train_dataloader) // 5\n",
    "            if (len(train_dataloader) - step - 1) % chunk_size == 0:\n",
    "                validation_results = evaluate_tiered(\n",
    "                    MaxStoryLength,\n",
    "                    tslm_model,\n",
    "                    trip_model,\n",
    "                    val_dataloader,\n",
    "                    device, [(accuracy_score, 'accuracy'), (f1_score, 'f1')],\n",
    "                    seg_mode=False,\n",
    "                    return_explanations=True,\n",
    "                    return_losses=True,\n",
    "                    verbose=False)\n",
    "                out = validation_results[16]\n",
    "\n",
    "                val_record = {\n",
    "                    'epoch':\n",
    "                    len(val_lc_data) - 1,\n",
    "                    'iteration':\n",
    "                    (len(val_lc_data) - 1) * len(train_dataloader) + step,\n",
    "                    'loss_preconditions':\n",
    "                    float(out['loss_preconditions'].detach().cpu().numpy()) /\n",
    "                    trip_model.num_attributes,\n",
    "                    'loss_effects':\n",
    "                    float(out['loss_effects'].detach().cpu().numpy()) /\n",
    "                    trip_model.num_attributes,\n",
    "                    'loss_conflicts':\n",
    "                    float(out['loss_conflicts'].detach().cpu().numpy()),\n",
    "                    'loss_stories':\n",
    "                    float(out['loss_stories'].detach().cpu().numpy()),\n",
    "                    'loss_total':\n",
    "                    float(out['total_loss'].detach().cpu().numpy())\n",
    "                }\n",
    "                val_lc_data[-1].append(val_record)\n",
    "\n",
    "        bar_idx += 1\n",
    "        bar.update(bar_idx)\n",
    "\n",
    "    bar.finish()\n",
    "\n",
    "    return total_loss / len(train_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
