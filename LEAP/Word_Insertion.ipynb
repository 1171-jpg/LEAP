{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7fd0f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloze label distribution (train):\n",
      "[(1, 400), (0, 399)]\n",
      "Cloze label distribution (dev):\n",
      "[(0, 161), (1, 161)]\n",
      "Cloze label distribution (test):\n",
      "[(1, 176), (0, 175)]\n"
     ]
    }
   ],
   "source": [
    "DRIVE_PATH = ''\n",
    "mode = 'roberta' \n",
    "task_name = 'trip'\n",
    "debug = False\n",
    "config_batch_size = 1\n",
    "config_lr = 1e-6\n",
    "config_epochs = 15\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "import json\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "model_name = 'roberta-large'\n",
    "from transformers import RobertaTokenizerFast\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-large')\n",
    "from transformers import RobertaConfig,RobertaModel,AdamW\n",
    "config_class = RobertaConfig\n",
    "emb_class = RobertaModel\n",
    "from www.utils import print_dict\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "data_file = os.path.join('../Source_task/trip.json')\n",
    "with open(data_file, 'r') as f:\n",
    "    cloze_dataset_2s, order_dataset_2s = json.load(f)  \n",
    "\n",
    "for p in cloze_dataset_2s:\n",
    "    label_dist = Counter([ex['label'] for ex in cloze_dataset_2s[p]])\n",
    "    print('Cloze label distribution (%s):' % p)\n",
    "    print(label_dist.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405d0678",
   "metadata": {},
   "source": [
    "#### load nlpaug model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bbc3ec",
   "metadata": {},
   "source": [
    "### Notice, as the limitatition of upload file size, to use this data augmentation, please download the corresponding model from https://github.com/makcedward/nlpaug and put the file in **nlpaug_model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_DIR\"] = '../nlpaug_model'\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdbce46",
   "metadata": {},
   "source": [
    "#### Load trip dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee60615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from www.dataset.prepro import get_tiered_data, balance_labels\n",
    "from www.dataset.adaptation import ReOrderDataset,add_bert_features_tiered_modify,add_bert_features_tiered_dummy,get_tensor_dataset_tiered_dummy\n",
    "from collections import Counter\n",
    "tiered_dataset = cloze_dataset_2s\n",
    "\n",
    "# Debug the code on a small amount of data\n",
    "if False:\n",
    "    for k in tiered_dataset:\n",
    "        tiered_dataset[k] = tiered_dataset[k][:5]\n",
    "\n",
    "maxStoryLength=168       \n",
    "tiered_dataset = get_tiered_data(tiered_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f291dc70",
   "metadata": {},
   "source": [
    "#### load another dataset and do insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbcade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = os.path.join('../Source_task/trip.json')\n",
    "with open(data_file, 'r') as f:\n",
    "    new_cloze_dataset_2s, order_dataset_2s = json.load(f)  \n",
    "    \n",
    "abstract_dataset = new_cloze_dataset_2s\n",
    "maxStoryLength=168      \n",
    "\n",
    "if False:\n",
    "    for k in abstract_dataset:\n",
    "        abstract_dataset[k] = abstract_dataset[k][:5]\n",
    "\n",
    "abstract_dataset = get_tiered_data(abstract_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story_pair in tqdm(abstract_dataset['train']):\n",
    "    for sample_story in story_pair['stories']:\n",
    "        entity_list = [_['entity'] for _ in sample_story['entities']]\n",
    "        aug_sentence_list=[]\n",
    "        for sentence in sample_story['sentences']:\n",
    "            activate_entity_list =[]\n",
    "             ### get contained entity\n",
    "            for entity in entity_list:\n",
    "                if entity in sentence:\n",
    "                    activate_entity_list.append(entity)\n",
    "        #     print(sentence)\n",
    "        #     print(activate_entity_list)  \n",
    "            ### get aug sentence\n",
    "            while True:\n",
    "                valid_flag = True\n",
    "                aug_sentence = aug.augment(sentence)[0]\n",
    "        #         print(aug_sentence)\n",
    "                for entity in activate_entity_list:\n",
    "                    if entity not in aug_sentence:\n",
    "                        valid_flag = False\n",
    "                if valid_flag:\n",
    "                    break\n",
    "            aug_sentence_list.append(aug_sentence)\n",
    "\n",
    "        sample_story['sentences'] = aug_sentence_list\n",
    "        for entity in sample_story['entities']:\n",
    "            entity['sentences'] = aug_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiered_dataset['train'] = tiered_dataset['train'] + abstract_dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf4331d",
   "metadata": {},
   "source": [
    "#### Process new training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c74b3583",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiered_dataset = add_bert_features_tiered_modify(tiered_dataset, tokenizer,maxStoryLength, add_segment_ids=True)\n",
    "tiered_dataset = add_bert_features_tiered_dummy(tiered_dataset, tokenizer,maxStoryLength, add_segment_ids=True)\n",
    "tiered_dataset = ReOrderDataset(tiered_dataset)\n",
    "\n",
    "tiered_tensor_dataset = {}\n",
    "max_story_length = max([len(ex['stories'][0]['sentences']) for p in tiered_dataset for ex in tiered_dataset[p]])\n",
    "for p in tiered_dataset:\n",
    "    tiered_tensor_dataset[p] = get_tensor_dataset_tiered_dummy(tiered_dataset[p], max_story_length, maxStoryLength,add_segment_ids=True)\n",
    "    \n",
    "    \n",
    "from www.dataset.ann import att_to_idx, att_to_num_classes, att_types\n",
    "\n",
    "subtask = 'cloze'\n",
    "batch_sizes = [config_batch_size]\n",
    "learning_rates = [config_lr]\n",
    "epochs = config_epochs\n",
    "eval_batch_size = 16\n",
    "generate_learning_curve = True # Generate data for training curve figure in TRIP paper\n",
    "\n",
    "num_state_labels = {}\n",
    "for att in att_to_idx:\n",
    "    if att_types[att] == 'default':\n",
    "        num_state_labels[att_to_idx[att]] = 3\n",
    "    else:\n",
    "        num_state_labels[att_to_idx[att]] = att_to_num_classes[att] # Location attributes fall into this since they don't have well-define pre- and post-condition yet\n",
    "\n",
    "ablation = ['attributes', 'states-logits'] # This is the default mode presented in the paper    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd96d06",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b546e0fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from www.utils import print_dict, get_model_dir\n",
    "# Modify\n",
    "from Method_Joint import getLengthMask,compute_metrics,update_result,evaluation_joint_model_dummy,train_model_joint_dummy,eval_model_joint_dummy,verifiable_reasoning,save_results\n",
    "from Model_Joint import RobertaProceduralTSLMJointDummySoft\n",
    "from www.dataset.ann import att_to_num_classes\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "seed_val = 14 # Save random seed for reproducibility\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "train_sampler = RandomSampler(tiered_tensor_dataset['train'])\n",
    "train_dataloader = DataLoader(tiered_tensor_dataset['train'], sampler=train_sampler, batch_size=1)\n",
    "dev_sampler = SequentialSampler(tiered_tensor_dataset['dev'])\n",
    "dev_dataloader = DataLoader(tiered_tensor_dataset['dev'], sampler=dev_sampler, batch_size=1)\n",
    "\n",
    "config = config_class.from_pretrained(model_name)  \n",
    "device=\"cuda:0\"\n",
    "num_attributes=len(num_state_labels)\n",
    "max_story_length = max([len(ex['stories'][0]['sentences']) for p in tiered_dataset for ex in tiered_dataset[p]])\n",
    "\n",
    "story_loss=True \n",
    "story_back=True\n",
    "scheduler=True\n",
    "tslm= RobertaProceduralTSLMJointDummySoft.from_pretrained('tli8hf/unqover-roberta-large-squad', return_dict=True,num_attributes=num_attributes,labels_per_att=num_state_labels,story_loss=story_loss,story_back=story_back).to(device)\n",
    "tslm_optimizer = AdamW(tslm.parameters(), lr=config_lr)\n",
    "if scheduler:\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(tslm_optimizer, num_warmup_steps=0, num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c70eb4",
   "metadata": {},
   "source": [
    "#### Train model within source task`\n",
    "**Notice** we do data augmentation on Joint Model with story centric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8bd1423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('\\nTRAINING MODEL')\n",
    "best_accuracy=0\n",
    "best_verifiability=0\n",
    "best_accuracy_dir=\"\"\n",
    "best_verifiability_dir=\"\"\n",
    "grad_accmu=2\n",
    "loss_adjust=[0.4,0.4,0.1,0.1]\n",
    "DRIVE_PATH=\"Word_Insertion\"\n",
    "sentence_tag = False\n",
    "\n",
    "for epoch_number in range(epochs):\n",
    "    print(\"Start Training in epoch #{}\".format(epoch_number))\n",
    "    train_lc_data = []\n",
    "    tslm.train()\n",
    "    for layer in tslm.precondition_classifiers:\n",
    "        layer.train()\n",
    "    for layer in tslm.effect_classifiers:\n",
    "        layer.train()    \n",
    "    for batch in tqdm(train_dataloader):\n",
    "        final_out=train_model_joint_dummy(batch,num_attributes,device,tslm,tslm_optimizer\\\n",
    "                                    ,grad_accmu,loss_adjust=loss_adjust)\n",
    "        train_lc_data.append({'loss_preconditions':float(final_out['loss_preconditions'].detach().cpu().numpy()),\n",
    "                              'loss_effects': float(final_out['loss_effects'].detach().cpu().numpy()),\n",
    "                              'loss_conflicts': float(final_out['loss_conflicts'].detach().cpu().numpy()),\n",
    "                              'loss_stories': float(final_out['loss_story'].detach().cpu().numpy()),\n",
    "                              'loss_total': float(final_out['total_loss'].detach().cpu().numpy())})\n",
    "        \n",
    "        \n",
    "    print(\"Start Evaluation in epoch #{}\".format(epoch_number))\n",
    "    tslm.eval()\n",
    "    for layer in tslm.precondition_classifiers:\n",
    "        layer.eval()\n",
    "    for layer in tslm.effect_classifiers:\n",
    "        layer.eval()    \n",
    "    metr_prec,metr_eff,metr_conflicts,metr_stories,verifiability,consistency, explanations\\\n",
    "    =evaluation_joint_model_dummy(max_story_length,num_attributes,tslm,tslm_optimizer,dev_dataloader,device,sentence_tag=sentence_tag)\n",
    "    accuracy=metr_stories['accuracy']\n",
    "    metr_stories['consistency']=consistency\n",
    "    metr_stories['verifiability']=verifiability\n",
    "    \n",
    "    \n",
    "    # save metrics\n",
    "    task_name=\"trip_%s_dev\"\n",
    "    output_model_path=os.path.join(DRIVE_PATH,str(epoch_number))\n",
    "    if not os.path.exists(output_model_path):\n",
    "        os.makedirs(output_model_path)\n",
    "    save_results(metr_prec, output_model_path, task_name % 'preconditions')\n",
    "    save_results(metr_eff, output_model_path, task_name % 'effects')\n",
    "    save_results(metr_conflicts, output_model_path, task_name % 'conflicts')\n",
    "    save_results(metr_stories, output_model_path, task_name % 'stories')\n",
    "    save_results(explanations, output_model_path, task_name % 'explanations')   \n",
    "    train_lc_data = pd.DataFrame(train_lc_data)\n",
    "    train_lc_data.to_csv(os.path.join(output_model_path, 'learning_curve_data_train.csv'), index=False)\n",
    "\n",
    "    \n",
    "    model_dir=os.path.join(output_model_path, 'tslm.pth')\n",
    "    torch.save(tslm, model_dir)\n",
    "    \n",
    "    if best_accuracy < accuracy:\n",
    "        best_accuracy=accuracy\n",
    "        best_accuracy_dir=model_dir\n",
    "    if best_verifiability < verifiability:\n",
    "        best_verifiability=verifiability\n",
    "        best_verifiability_dir=model_dir\n",
    "    print(\"accuracy {}\".format(accuracy))\n",
    "    print(\"consistency {}\".format(consistency))\n",
    "    print(\"verifiability {}\".format(verifiability))\n",
    "print(\"Traing Process Finish\")\n",
    "print(\"Achieve best accuracy {} at {}\".format(best_accuracy,best_accuracy_dir))\n",
    "print(\"Achieve best verifiability {} at {}\".format(best_verifiability,best_verifiability_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ab9bfc",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd923a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in tiered_dataset:\n",
    "    if p != 'test':\n",
    "        continue\n",
    "\n",
    "    p_dataset = tiered_dataset[p]\n",
    "    p_tensor_dataset = tiered_tensor_dataset[p]\n",
    "    p_sampler = SequentialSampler(p_tensor_dataset)\n",
    "    p_dataloader = DataLoader(p_tensor_dataset,\n",
    "                              sampler=p_sampler,\n",
    "                              batch_size=1)\n",
    "    task_name = 'trip' + '_%s_' + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03312a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dir_file=DRIVE_PATH\n",
    "for i in range(15):\n",
    "    file_number=str(i)\n",
    "    output_model_path=os.path.join(Dir_file, file_number)\n",
    "    tslm = torch.load(os.path.join(output_model_path, 'tslm.pth'))\n",
    "    print(\"Start Evaluation in epoch #{}\".format(i))\n",
    "    tslm.eval()\n",
    "    metr_prec,metr_eff,metr_conflicts,metr_stories,verifiability,consistency, explanations\\\n",
    "    =evaluation_joint_model_dummy(max_story_length,num_attributes,tslm,tslm_optimizer,dev_dataloader,device,sentence_tag=sentence_tag)\n",
    "    accuracy=metr_stories['accuracy']\n",
    "    metr_stories['consistency']=consistency\n",
    "    metr_stories['verifiability']=verifiability\n",
    "    print(\"accuracy {}\".format(accuracy))\n",
    "    print(\"consistency {}\".format(consistency))\n",
    "    print(\"verifiability {}\".format(verifiability))\n",
    "    save_results(metr_prec, output_model_path, task_name % 'preconditions')\n",
    "    save_results(metr_eff, output_model_path, task_name % 'effects')\n",
    "    save_results(metr_conflicts, output_model_path, task_name % 'conflicts')\n",
    "    save_results(metr_stories, output_model_path, task_name % 'stories')\n",
    "    save_results(explanations, output_model_path, task_name % 'explanations') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae983a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
