{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a474ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVE_PATH = ''\n",
    "mode = 'roberta' \n",
    "task_name = 'trip'\n",
    "debug = False\n",
    "config_batch_size = 1\n",
    "config_lr = 1e-5 \n",
    "config_epochs = 15\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "import json\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from Methods_for_zero_inference import *\n",
    "model_name = 'roberta-large'\n",
    "from transformers import RobertaTokenizerFast\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-large')\n",
    "from transformers import RobertaConfig,RobertaModel,AdamW\n",
    "config_class = RobertaConfig\n",
    "emb_class = RobertaModel\n",
    "from www.utils import print_dict\n",
    "import json\n",
    "from collections import Counter\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "from spacy.lang.en import English\n",
    "nlp_sen = English()\n",
    "config = {\"punct_chars\": None}\n",
    "nlp_sen.add_pipe(\"sentencizer\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59dc3dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed126b06",
   "metadata": {},
   "source": [
    "#### Load presetting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e798b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from Model_Joint import RobertaProceduralTSLMJointDummySoft\n",
    "from www.dataset.ann import att_to_idx, att_to_num_classes, att_types\n",
    "\n",
    "num_state_labels = {}\n",
    "for att in att_to_idx:\n",
    "    if att_types[att] == 'default':\n",
    "        num_state_labels[att_to_idx[att]] = 3\n",
    "    else:\n",
    "        num_state_labels[att_to_idx[att]] = att_to_num_classes[att] # Location attributes fall into this since they don't have well-define pre- and post-condition yet\n",
    "\n",
    "seed_val = 22 # Save random seed for reproducibility\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "config = config_class.from_pretrained(model_name)  \n",
    "device=\"cuda:0\"\n",
    "num_attributes=len(num_state_labels)\n",
    "\n",
    "story_loss=False\n",
    "story_back=False\n",
    "tslm= RobertaProceduralTSLMJointDummySoft.from_pretrained('tli8hf/unqover-roberta-large-squad', return_dict=True,num_attributes=num_attributes,labels_per_att=num_state_labels,story_loss=story_loss,story_back=story_back).to(device)\n",
    "tslm_optimizer = AdamW(tslm.parameters(), lr=config_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb83aa",
   "metadata": {},
   "source": [
    "### aNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "388a5abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = np.load('../Labeler/Participant_Extraction/Final_Participant/ANLI_Participant_IJCAI.npy',allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a608cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = orderdata(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d21a3c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add input feature joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1532/1532 [00:06<00:00, 244.04it/s]\n"
     ]
    }
   ],
   "source": [
    "Maxlength=100\n",
    "dev_dataset=add_input_feature_joint_soft_dummy(dev_dataset,tokenizer,Maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0254e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dev_dataset:\n",
    "    if len(sample['goal_sol_1'])!=len(sample['goal_sol_2']):\n",
    "        Maxlen=max(len(sample['goal_sol_1']),len(sample['goal_sol_2']))\n",
    "        Minlen=min(len(sample['goal_sol_1']),len(sample['goal_sol_2']))\n",
    "        Gap=Maxlen-Minlen\n",
    "        if len(sample['goal_sol_1'])<len(sample['goal_sol_2']):\n",
    "            for input_rep in sample['anli_input_1']:\n",
    "                for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                    input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))\n",
    "            input_rep=sample['anli_dummy_1']\n",
    "            for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))\n",
    "        else:\n",
    "            for input_rep in sample['anli_input_2']:\n",
    "                for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                    input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))\n",
    "            input_rep=sample['anli_dummy_2']\n",
    "            for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348528bc",
   "metadata": {},
   "source": [
    "#### zero inference on aNLI\n",
    "**file_path** contains the folder directory of model\n",
    "\n",
    "**model_name** contains the model name\n",
    "\n",
    "**sentence_tag** control the model is **sentencen-centric** or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25c3b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tag = True\n",
    "task=\"test\"\n",
    "file_path=\"The folder directory of model\"\n",
    "\n",
    "model_name = \"Model name\"\n",
    " \n",
    "Dir_file = model_name\n",
    "FILE_PATH = os.path.join(file_path,Dir_file)\n",
    "best_accuracy_model = find_best_model(FILE_PATH,task,15)\n",
    "file_number=str(best_accuracy_model)\n",
    "Epoch_number=file_number\n",
    "output_model_path=os.path.join(FILE_PATH, file_number)\n",
    "\n",
    "### zero inference \n",
    "\n",
    "tslm = torch.load(os.path.join(output_model_path, 'tslm.pth'))\n",
    "\n",
    "tslm.zero_grad()\n",
    "tslm.eval()\n",
    "for layer in tslm.precondition_classifiers:\n",
    "    layer.eval()\n",
    "for layer in tslm.effect_classifiers:\n",
    "    layer.eval()   \n",
    "\n",
    "sol_label_summary=None\n",
    "sol_pred_summary=None\n",
    "all_summary=[]\n",
    "with torch.no_grad():\n",
    "    for index,batch in enumerate(tqdm(dev_dataset)):\n",
    "        try:\n",
    "            sol_label = np.array([[batch['label']-1]])\n",
    "\n",
    "            sol_pred,batch_summary = predict_from_zero_shot_dummy(tslm,batch,device,sentence_tag)\n",
    "            batch_summary['index']=index\n",
    "            sol_pred=np.array([[sol_pred]])\n",
    "\n",
    "#             Summary the result\n",
    "            if sol_label_summary is None:\n",
    "                sol_label_summary = sol_label\n",
    "            else:\n",
    "                sol_label_summary = np.concatenate((sol_label_summary, sol_label), axis=0)\n",
    "\n",
    "            if sol_pred_summary is None:\n",
    "                sol_pred_summary = sol_pred\n",
    "            else:\n",
    "                sol_pred_summary = np.concatenate((sol_pred_summary, sol_pred), axis=0)\n",
    "\n",
    "\n",
    "            all_summary.append(batch_summary)\n",
    "        except:\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"Can not find entity at {}\".format(index))\n",
    "\n",
    "# Get the result\n",
    "metrics = [(accuracy_score, 'accuracy'),(f1_score, 'f1')]\n",
    "metr_stories = compute_metrics(sol_pred_summary.flatten(), sol_label_summary.flatten(), metrics)\n",
    "print(metr_stories['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70604a3e",
   "metadata": {},
   "source": [
    "### PIQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "393554d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = np.load('../Labeler/Participant_Extraction/Final_Participant/PIQA_Participant_IJCAI.npy',allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b419276",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = orderdata(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12b1ffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add input feature joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1838/1838 [00:13<00:00, 132.04it/s]\n"
     ]
    }
   ],
   "source": [
    "Maxlength=270\n",
    "dev_dataset=add_input_feature_joint_soft_dummy(dev_dataset,tokenizer,Maxlength)\n",
    "for sample in dev_dataset:\n",
    "    if len(sample['goal_sol_1'])!=len(sample['goal_sol_2']):\n",
    "        Maxlen=max(len(sample['goal_sol_1']),len(sample['goal_sol_2']))\n",
    "        Minlen=min(len(sample['goal_sol_1']),len(sample['goal_sol_2']))\n",
    "        Gap=Maxlen-Minlen\n",
    "        if len(sample['goal_sol_1'])<len(sample['goal_sol_2']):\n",
    "            for input_rep in sample['anli_input_1']:\n",
    "                for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                    input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))\n",
    "            input_rep=sample['anli_dummy_1']\n",
    "            for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))\n",
    "        else:\n",
    "            for input_rep in sample['anli_input_2']:\n",
    "                for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                    input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))\n",
    "            input_rep=sample['anli_dummy_2']\n",
    "            for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d868cba",
   "metadata": {},
   "source": [
    "#### zero inference on PIQA\n",
    "**file_path** contains the folder directory of model\n",
    "\n",
    "**model_name** contains the model name\n",
    "\n",
    "**sentence_tag** control the model is **sentencen-centric** or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc10c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tag = True\n",
    "\n",
    "\n",
    "task=\"test\"\n",
    "file_path=\"The folder directory of model\"\n",
    "\n",
    "model_name = \"Model name\"\n",
    " \n",
    "Dir_file = model_name\n",
    "FILE_PATH = os.path.join(file_path,Dir_file)\n",
    "best_accuracy_model = find_best_model(FILE_PATH,task,15)\n",
    "file_number=str(best_accuracy_model)\n",
    "Epoch_number=file_number\n",
    "output_model_path=os.path.join(FILE_PATH, file_number)\n",
    "\n",
    "### zero inference \n",
    "\n",
    "tslm = torch.load(os.path.join(output_model_path, 'tslm.pth'))\n",
    "\n",
    "tslm.zero_grad()\n",
    "tslm.eval()\n",
    "for layer in tslm.precondition_classifiers:\n",
    "    layer.eval()\n",
    "for layer in tslm.effect_classifiers:\n",
    "    layer.eval()   \n",
    "\n",
    "sol_label_summary=None\n",
    "sol_pred_summary=None\n",
    "all_summary=[]\n",
    "with torch.no_grad():\n",
    "    for index,batch in enumerate(tqdm(dev_dataset)):\n",
    "        try:\n",
    "            sol_label = np.array([[batch['label']]])\n",
    "\n",
    "            sol_pred,batch_summary = predict_from_zero_shot_dummy(tslm,batch,device,sentence_tag)\n",
    "            batch_summary['index']=index\n",
    "            sol_pred=np.array([[sol_pred]])\n",
    "\n",
    "#             Summary the result\n",
    "            if sol_label_summary is None:\n",
    "                sol_label_summary = sol_label\n",
    "            else:\n",
    "                sol_label_summary = np.concatenate((sol_label_summary, sol_label), axis=0)\n",
    "\n",
    "            if sol_pred_summary is None:\n",
    "                sol_pred_summary = sol_pred\n",
    "            else:\n",
    "                sol_pred_summary = np.concatenate((sol_pred_summary, sol_pred), axis=0)\n",
    "\n",
    "\n",
    "            all_summary.append(batch_summary)\n",
    "        except:\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"Can not find entity at {}\".format(index))\n",
    "\n",
    "# Get the result\n",
    "metrics = [(accuracy_score, 'accuracy'),(f1_score, 'f1')]\n",
    "metr_stories = compute_metrics(sol_pred_summary.flatten(), sol_label_summary.flatten(), metrics)\n",
    "print(metr_stories['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f090066",
   "metadata": {},
   "source": [
    "## ROCStoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13c7c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = np.load('../Labeler/Participant_Extraction/Final_Participant/ROC_Participant_IJCAI.npy',allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8bf782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = orderdata(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73ab7ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add input feature joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1871/1871 [00:18<00:00, 100.97it/s]\n"
     ]
    }
   ],
   "source": [
    "Maxlength=100\n",
    "dev_dataset=add_input_feature_joint_soft_dummy(dev_data,tokenizer,Maxlength)\n",
    "for sample in dev_dataset:\n",
    "    if len(sample['goal_sol_1'])!=len(sample['goal_sol_2']):\n",
    "        Maxlen=max(len(sample['goal_sol_1']),len(sample['goal_sol_2']))\n",
    "        Minlen=min(len(sample['goal_sol_1']),len(sample['goal_sol_2']))\n",
    "        Gap=Maxlen-Minlen\n",
    "        if len(sample['goal_sol_1'])<len(sample['goal_sol_2']):\n",
    "            for input_rep in sample['anli_input_1']:\n",
    "                for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                    input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))\n",
    "            input_rep=sample['anli_dummy_1']\n",
    "            for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))\n",
    "        else:\n",
    "            for input_rep in sample['anli_input_2']:\n",
    "                for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                    input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))\n",
    "            input_rep=sample['anli_dummy_2']\n",
    "            for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da1e866",
   "metadata": {},
   "source": [
    "#### zero inference on ROCStories\n",
    "**file_path** contains the folder directory of model\n",
    "\n",
    "**model_name** contains the model name\n",
    "\n",
    "**sentence_tag** control the model is **sentencen-centric** or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tag = True\n",
    "task=\"test\"\n",
    "file_path=\"The folder directory of model\"\n",
    "\n",
    "model_name = \"Model name\"\n",
    " \n",
    "Dir_file = model_name\n",
    "FILE_PATH = os.path.join(file_path,Dir_file)\n",
    "best_accuracy_model = find_best_model(FILE_PATH,task,15)\n",
    "file_number=str(best_accuracy_model)\n",
    "Epoch_number=file_number\n",
    "output_model_path=os.path.join(FILE_PATH, file_number)\n",
    "\n",
    "### zero inference \n",
    "\n",
    "tslm = torch.load(os.path.join(output_model_path, 'tslm.pth'))\n",
    "\n",
    "tslm.zero_grad()\n",
    "tslm.eval()\n",
    "for layer in tslm.precondition_classifiers:\n",
    "    layer.eval()\n",
    "for layer in tslm.effect_classifiers:\n",
    "    layer.eval()   \n",
    "\n",
    "sol_label_summary=None\n",
    "sol_pred_summary=None\n",
    "all_summary=[]\n",
    "with torch.no_grad():\n",
    "    for index,batch in enumerate(tqdm(dev_dataset)):\n",
    "        try:\n",
    "            sol_label = np.array([[batch['label']-1]])\n",
    "\n",
    "            sol_pred,batch_summary = predict_from_zero_shot_dummy(tslm,batch,device,sentence_tag)\n",
    "            batch_summary['index']=index\n",
    "            sol_pred=np.array([[sol_pred]])\n",
    "\n",
    "#             Summary the result\n",
    "            if sol_label_summary is None:\n",
    "                sol_label_summary = sol_label\n",
    "            else:\n",
    "                sol_label_summary = np.concatenate((sol_label_summary, sol_label), axis=0)\n",
    "\n",
    "            if sol_pred_summary is None:\n",
    "                sol_pred_summary = sol_pred\n",
    "            else:\n",
    "                sol_pred_summary = np.concatenate((sol_pred_summary, sol_pred), axis=0)\n",
    "\n",
    "\n",
    "            all_summary.append(batch_summary)\n",
    "        except:\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"Can not find entity at {}\".format(index))\n",
    "\n",
    "# Get the result\n",
    "metrics = [(accuracy_score, 'accuracy'),(f1_score, 'f1')]\n",
    "metr_stories = compute_metrics(sol_pred_summary.flatten(), sol_label_summary.flatten(), metrics)\n",
    "print(metr_stories['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f49a7",
   "metadata": {},
   "source": [
    "## CODAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1740c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = np.load('../Labeler/Participant_Extraction/Final_Participant/CODAH_Participant_IJCAI.npy',allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8850a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dev_dataset:\n",
    "    common_list=set(sample['entity'][0])&set(sample['entity'][1])&set(sample['entity'][2])&set(sample['entity'][3])\n",
    "    common_list=sorted(list(common_list))\n",
    "    sample['common_entity']=len(common_list)\n",
    "    for index,entity in enumerate(sample['entity']):\n",
    "        sample['entity'][index]=common_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5f377d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add input feature joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2776/2776 [00:14<00:00, 192.19it/s]\n"
     ]
    }
   ],
   "source": [
    "Maxlength=105\n",
    "dev_dataset=add_input_feature_joint_soft_dummy_codah(dev_dataset,tokenizer,Maxlength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c6b7c",
   "metadata": {},
   "source": [
    "#### zero inference on CODAH\n",
    "**file_path** contains the folder directory of model\n",
    "\n",
    "**model_name** contains the model name\n",
    "\n",
    "**sentence_tag** control the model is **sentencen-centric** or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3281ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tag = True\n",
    "task=\"test\"\n",
    "file_path=\"The folder directory of model\"\n",
    "\n",
    "model_name = \"Model name\"\n",
    " \n",
    "Dir_file = model_name\n",
    "FILE_PATH = os.path.join(file_path,Dir_file)\n",
    "best_accuracy_model = find_best_model(FILE_PATH,task,15)\n",
    "file_number=str(best_accuracy_model)\n",
    "Epoch_number=file_number\n",
    "output_model_path=os.path.join(FILE_PATH, file_number)\n",
    "\n",
    "### zero inference \n",
    "\n",
    "tslm = torch.load(os.path.join(output_model_path, 'tslm.pth'))\n",
    "\n",
    "tslm.zero_grad()\n",
    "tslm.eval()\n",
    "for layer in tslm.precondition_classifiers:\n",
    "    layer.eval()\n",
    "for layer in tslm.effect_classifiers:\n",
    "    layer.eval()   \n",
    "\n",
    "sol_label_summary=None\n",
    "sol_pred_summary=None\n",
    "all_summary=[]\n",
    "with torch.no_grad():\n",
    "    for index,batch in enumerate(tqdm(dev_dataset)):\n",
    "        try:\n",
    "            sol_label = np.array([[batch['label']-1]])\n",
    "\n",
    "            sol_pred,batch_summary = predict_from_zero_shot_dummy_codah(tslm,batch,device,sentence_tag)\n",
    "            batch_summary['index']=index\n",
    "            sol_pred=np.array([[sol_pred]])\n",
    "\n",
    "#             Summary the result\n",
    "            if sol_label_summary is None:\n",
    "                sol_label_summary = sol_label\n",
    "            else:\n",
    "                sol_label_summary = np.concatenate((sol_label_summary, sol_label), axis=0)\n",
    "\n",
    "            if sol_pred_summary is None:\n",
    "                sol_pred_summary = sol_pred\n",
    "            else:\n",
    "                sol_pred_summary = np.concatenate((sol_pred_summary, sol_pred), axis=0)\n",
    "\n",
    "\n",
    "            all_summary.append(batch_summary)\n",
    "        except:\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"Can not find entity at {}\".format(index))\n",
    "\n",
    "# Get the result\n",
    "metrics = [(accuracy_score, 'accuracy'),(f1_score, 'f1')]\n",
    "metr_stories = compute_metrics(sol_pred_summary.flatten(), sol_label_summary.flatten(), metrics)\n",
    "print(metr_stories['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9dc5ae",
   "metadata": {},
   "source": [
    "## RICA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666a4af0",
   "metadata": {},
   "source": [
    "#### zero inference on RICA\n",
    "Notice: All participants in RICA are noval desigend new term, so we don't include participants annotatoin on RICA.\n",
    "**file_path** contains the folder directory of model\n",
    "\n",
    "**model_name** contains the model name\n",
    "\n",
    "**sentence_tag** control the model is **sentencen-centric** or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0afe9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences=[]\n",
    "with open('../Target_task/test_sentences.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        test_sentences.append(line.replace('\\n',''))\n",
    "\n",
    "test_sentences_masks = []\n",
    "with open('../Target_task/test_sentences_m.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        test_sentences_masks.append(line.replace('\\n',''))\n",
    "\n",
    "import ast\n",
    "test_sentences_mask_pairs = []\n",
    "with open('../Target_task/config.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        test_sentences_mask_pairs.append(ast.literal_eval(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a66e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = []\n",
    "count = 0\n",
    "for correct_sen,correct_word,mask_pair in zip(test_sentences,test_sentences_masks,test_sentences_mask_pairs):\n",
    "    mask_pair.remove(correct_word)\n",
    "    incorrect_word = mask_pair[0]\n",
    "    wrong_sen = correct_sen.replace(correct_word,incorrect_word)\n",
    "    sample_story = {}\n",
    "    sample_story['goal_sol_1'] = [_.strip() for _ in correct_sen.split(\",\")]\n",
    "    sample_story['word_list'] = [correct_word,incorrect_word]\n",
    "    sample_story['goal_sol_2'] = [_.strip() for _ in wrong_sen.split(\",\")]\n",
    "    sample_story['entity_1']=[]\n",
    "    sample_story['entity_2']=[]\n",
    "    sample_story['common_entity']=0\n",
    "    sample_story['label']=0    \n",
    "    dev_data.append(sample_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "Maxlength=100\n",
    "dev_dataset=add_input_feature_joint_soft_dummy(dev_data,tokenizer,Maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796df527",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dev_dataset:\n",
    "#     if (len(sample['entity_1'])+len(sample['entity_2']))==0:\n",
    "#         count+=1\n",
    "    if len(sample['goal_sol_1'])!=len(sample['goal_sol_2']):\n",
    "        print(1)\n",
    "        Maxlen=max(len(sample['goal_sol_1']),len(sample['goal_sol_2']))\n",
    "        Minlen=min(len(sample['goal_sol_1']),len(sample['goal_sol_2']))\n",
    "        Gap=Maxlen-Minlen\n",
    "        if len(sample['goal_sol_1'])<len(sample['goal_sol_2']):\n",
    "            for input_rep in sample['anli_input_1']:\n",
    "                for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                    input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))\n",
    "            input_rep=sample['anli_dummy_1']\n",
    "            for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))\n",
    "        else:\n",
    "            for input_rep in sample['anli_input_2']:\n",
    "                for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                    input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))\n",
    "            input_rep=sample['anli_dummy_2']\n",
    "            for key in ['input_ids','attention_mask','timestamp_id']:\n",
    "                input_rep[key]=torch.cat((input_rep[key],torch.zeros([Gap,Maxlength])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3210e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tag = True\n",
    "task=\"test\"\n",
    "file_path=\"The folder directory of model\"\n",
    "\n",
    "model_name = \"Model name\"\n",
    " \n",
    "Dir_file = model_name\n",
    "FILE_PATH = os.path.join(file_path,Dir_file)\n",
    "best_accuracy_model = find_best_model(FILE_PATH,task,15)\n",
    "file_number=str(best_accuracy_model)\n",
    "Epoch_number=file_number\n",
    "output_model_path=os.path.join(FILE_PATH, file_number)\n",
    "\n",
    "### zero inference \n",
    "\n",
    "tslm = torch.load(os.path.join(output_model_path, 'tslm.pth'))\n",
    "\n",
    "tslm.zero_grad()\n",
    "tslm.eval()\n",
    "for layer in tslm.precondition_classifiers:\n",
    "    layer.eval()\n",
    "for layer in tslm.effect_classifiers:\n",
    "    layer.eval()   \n",
    "\n",
    "sol_label_summary=None\n",
    "sol_pred_summary=None\n",
    "all_summary=[]\n",
    "with torch.no_grad():\n",
    "    for index,batch in enumerate(tqdm(dev_dataset)):\n",
    "        try:\n",
    "            sol_label = np.array([[batch['label']-1]])\n",
    "\n",
    "            sol_pred,batch_summary = predict_from_zero_shot_dummy(tslm,batch,device,sentence_tag)\n",
    "            batch_summary['index']=index\n",
    "            sol_pred=np.array([[sol_pred]])\n",
    "\n",
    "#             Summary the result\n",
    "            if sol_label_summary is None:\n",
    "                sol_label_summary = sol_label\n",
    "            else:\n",
    "                sol_label_summary = np.concatenate((sol_label_summary, sol_label), axis=0)\n",
    "\n",
    "            if sol_pred_summary is None:\n",
    "                sol_pred_summary = sol_pred\n",
    "            else:\n",
    "                sol_pred_summary = np.concatenate((sol_pred_summary, sol_pred), axis=0)\n",
    "\n",
    "\n",
    "            all_summary.append(batch_summary)\n",
    "        except:\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"Can not find entity at {}\".format(index))\n",
    "\n",
    "# Get the result\n",
    "metrics = [(accuracy_score, 'accuracy'),(f1_score, 'f1')]\n",
    "metr_stories = compute_metrics(sol_pred_summary.flatten(), sol_label_summary.flatten(), metrics)\n",
    "print(metr_stories['accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
